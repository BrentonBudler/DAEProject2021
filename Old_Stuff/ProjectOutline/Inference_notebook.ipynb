{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.png\" width=200, height=200>\n",
    "\n",
    "<h1><center>Inference: Socio-economic wellness of South Africa</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-7c6c464dc61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.utils import resample\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The earnings gap between men and women is often referenced and has received a lot of attention in the media (https://www.thesouthafrican.com/news/gender-pay-gap-south-africa-charts/ ). However, while gender may be related to the monthly earnings of people in South Africa, it is also possible that other variables are contributing to this gap in earnings. In this project, I investigate some factors that may be related to the monthly earnings of the people of South Africa, in addition to gender. \n",
    "\n",
    "### Research question\n",
    "\n",
    "Aside from gender, are there other factors that affect the monthly earnings of a person in South Africa?\n",
    "\n",
    "### Hypothesis\n",
    "In addition to gender, there is also a relationship between a person's education, work and location and their monthly earnings in South Africa.\n",
    "\n",
    "In order to test this hypothesis, data has been obtained from the Labour Market Dynamics surveys published by Stats SA. Variables of interest have been extracted and have been used to fit regression models to establish whether the variable are significantly related to the monthly earnings. In the following section, the data used in this project is described.\n",
    "\n",
    "### Methodology\n",
    "A brief overview of the methodology is as follows:<br/>\n",
    "1. Read in data <br/>\n",
    "2. Encode variables <br/>\n",
    "3. Exploratory plots <br/>\n",
    "4. Initial modelling <br/>\n",
    "5. Feature selection using step-wise regression <br/>\n",
    "6. Bootstrapping for feature selection and testing<br/>\n",
    "7. Comparison of regression coefficient over the years <br/>\n",
    "\n",
    "More in-depth explanation of the steps in the methodology will be provided in the relevant sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labour Market Dynamics - Unemployment\n",
    "The Quarterly Labour Force Survey (QLFS) is a household-based sample survey conducted by Statistics South Africa (Stats SA). It collects data on the labour market activities of individuals aged 15 years or older who live in South Africa. Since 2008, Stats SA have generated an annual report which is released under the name \"Labour Market Dynamics in South Africa\". This report is constructed using data from a version of the pooled data from all four quarters (all four QLFS datasets in the year) and is ascribed the same nomenclature. \n",
    "\n",
    "In this section, the Labour Market Dynamics surveys for the years 2013-2017 is explored. Each survey is read in seperately and then concatenated to provide time series data. Only records with a valid value for monthly earnings are considered."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are various variables of interest in this study. In this section the variables of interest will be briefly described:\n",
    "<br/>\n",
    "Personal: Gender, Age, Marital status<br/>\n",
    "Education: Education status, Study field<br/>\n",
    "Location: Province, Geotype<br/>\n",
    "Work: Occupation, Industry, Multiple jobs, Hours worked, Sector<br/>\n",
    "\n",
    "##### Province\n",
    "The province where the respondent resides. The values are as follows:\n",
    "\n",
    "1 - Western Cape<br/>\n",
    "2 - Eastern Cape<br/>\n",
    "3 - Northern Cape<br/>\n",
    "4 - Free State<br/>\n",
    "5 - KwaZulu-Natal<br/>\n",
    "6 - North West<br/>\n",
    "7 - Gauteng<br/>\n",
    "8 - Mpumalanga<br/>\n",
    "9 - Limpopo<br/>\n",
    "\n",
    "##### Gender\n",
    "The gender of the respondent\n",
    "\n",
    "1 - Male<br/>\n",
    "2 - Female<br/>\n",
    "\n",
    "##### Age\n",
    "The age of the respondent\n",
    "\n",
    "##### Marital Status\n",
    "The marital status of the respondent. The values are as follows:\n",
    "\n",
    "1 - Married<br/>\n",
    "2 - Living together like husband and wife<br/>\n",
    "3 - Widow/Widower<br/>\n",
    "4 - Divorced or seperated<br/>\n",
    "5 - Never married<br/>\n",
    "\n",
    "##### Study field\n",
    "This variable applies to respondets that have obtained a post-school qualification. This indicates the field in which the post-school qualification was obtained.\n",
    "\n",
    "1 - Agriculture or Renewable natural resources<br/>\n",
    "2 - Architecture or environmental design<br/>\n",
    "3 - Arts; Visual or Performing<br/>\n",
    "4 - Business; commerce and management studies<br/>\n",
    "5 - Communication<br/>\n",
    "6 - Computer science<br/>\n",
    "7 - Education; training or development<br/>\n",
    "8 - Engineering or engineering technology<br/>\n",
    "9 - Health care or health sciences<br/>\n",
    "10 - Home economics<br/>\n",
    "11 - Industrial arts; traders or technology<br/>\n",
    "12 - Languages; linguistic or literature<br/>\n",
    "13 - Law<br/>\n",
    "14 - Libraries or museums<br/>\n",
    "15 - Life sciences or physical sciences<br/>\n",
    "16 - Mathematical sciences<br/>\n",
    "17 - Military sciences<br/>\n",
    "18 - Philosophy; religion or theology<br/>\n",
    "19 - Physical education or leisure<br/>\n",
    "20 - Psychology<br/>\n",
    "21 - Public administration or social services<br/>\n",
    "22 - Social sciences or social studies<br/>\n",
    "23 - Other<br/>\n",
    "24 - Management<br/>\n",
    "25 - Marketing<br/>\n",
    "26 - Information technology and computer science<br/>\n",
    "27 - Finance; economics and accounting<br/>\n",
    "28 - Office administration<br/>\n",
    "29 - Electrical infrastructure construction<br/>\n",
    "30 - Civil engineering and building construction<br/>\n",
    "31 - Engineering<br/>\n",
    "32 - Primary agriculture<br/>\n",
    "33 - Hospitality<br/>\n",
    "34 - Tourism<br/>\n",
    "35 - Safety in society<br/>\n",
    "36 - Mechatronics<br/>\n",
    "37 - Education and development<br/>\n",
    "\n",
    "##### Multiple jobs\n",
    "Indicates whether the respondent has multiple jobs.\n",
    "\n",
    "1 - Yes<br/>\n",
    "2 - No<br/>\n",
    "\n",
    "##### Occupation\n",
    "Indicates the occupation of the respondent.\n",
    "\n",
    "1 - Legislators; senior officials and managers<br/> \n",
    "2 - Professionals<br/> \n",
    "3 - Technical and associate professionals<br/> \n",
    "4 - Clerks<br/> \n",
    "5 - Service workers and shop and market sales workers<br/> \n",
    "6 - Skilled agricultural and fishery workers<br/> \n",
    "7 - Craft and related trades workers<br/> \n",
    "8 - Plant and machine operators and assemblers<br/> \n",
    "9 - Elementary Occupation<br/> \n",
    "10 - Domestic workers<br/> \n",
    "11 - Other occupation<br/> \n",
    "\n",
    "##### Industry\n",
    "Indicates the industry in which the respondent works\n",
    "\n",
    "1 - Agriculture; hunting; forestry and fishing<br/>\n",
    "2 - Mining and quarrying<br/>\n",
    "3 - Manufacturing<br/>\n",
    "4 - Electricity; gas and water supply<br/>\n",
    "5 - Construction<br/>\n",
    "6 - Wholesale and retail trade<br/>\n",
    "7 - Transport; storage and communication<br/>\n",
    "8 - Financial intermediation; insurance; real estate and business services<br/>\n",
    "9 - Community; social and personal services<br/>\n",
    "10 - Private households<br/>\n",
    "11 - Other<br/>\n",
    "\n",
    "##### Hours worked\n",
    "Indicates how many hours the respondent usually works every week\n",
    "\n",
    "##### Salary\n",
    "Indicates the total earnings the respondent earns every month\n",
    "\n",
    "##### Geo Type\n",
    "The type of geography of the area in which the respondent lives\n",
    "\n",
    "1 - Urban formal<br/>\n",
    "2 - Urban informal<br/>\n",
    "4 - Tribal areas<br/>\n",
    "5 - Rural formal<br/>\n",
    "\n",
    "##### Sector\n",
    "The sector in which the respondent works\n",
    "\n",
    "1 - Formal sector (non-agricultural)<br/>\n",
    "2 - Informal sector (non-agricultural)<br/>\n",
    "3 - Agriculture<br/>\n",
    "4 - Private households<br/>\n",
    "\n",
    "##### Education status\n",
    "The variable indicates the level of education obtained by the respondent.\n",
    "\n",
    "1 - No schooling<br/>\n",
    "2 - Less than primary completed<br/>\n",
    "3 - Primary completed<br/>\n",
    "4 - Secondary not completed<br/>\n",
    "5 - Secondary completed<br/>\n",
    "6 - Tertiary<br/>\n",
    "7 - Other<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column names that will be used for the dataset\n",
    "labels=['Province','Gender','Age','Marital_status','Study_field','Multiple_jobs','Occupation','Industry',\\\n",
    "       'Hours_worked','Salary','Geotype','Sector','Edu_status']\n",
    "labels_all=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2013=pd.read_csv(\"Labour/qlfs!annual!2013!final_F1.csv\")\n",
    "L2013=L2013[L2013['Q54a_monthly'].isna()==False] # remove records that do not have valid earnings values\n",
    "L2013=L2013[['Province','Q13GENDER','Q14AGE','Q16MARITALSTATUS','Q18FIELD',\\\n",
    "            'Q41MULTIPLEJOBS','occup','indus','Q418HRSWRK','Q54a_monthly','Geo_type','sector1','Education_Status']]\n",
    "L2013.columns=labels\n",
    "L2013=L2013.fillna(88888888) # fill missing values with a dummy value\n",
    "objects=L2013.select_dtypes(include=['float64']).columns\n",
    "L2013[objects]=L2013[objects].astype('int64') # convert all numerical values to integers\n",
    "L2013_filtered=L2013[L2013['Salary']<88888888] # remove records that do not have valid earnings values\n",
    "L2013_filtered.loc[:,'Year']=2013 # add year variable to identify data from different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2014=pd.read_csv(\"Labour/LMD!2014_F1.csv\")\n",
    "L2014=L2014[L2014['Q54A_MONTHLY'].isna()==False] # remove records that do not have valid earnings values\n",
    "L2014=L2014[['PROVINCE','Q13GENDER','Q14AGE','Q16MARITALSTATUS','Q18FIELD',\\\n",
    "            'Q41MULTIPLEJOBS','OCCUP','INDUS','HRSWRK','Q54A_MONTHLY','GEO_TYPE','SECTOR1','EDUCATION_STATUS']]\n",
    "L2014.columns=labels\n",
    "L2014=L2014.fillna(88888888) # fill missing values with a dummy value\n",
    "objects=L2014.select_dtypes(include=['float64']).columns\n",
    "L2014[objects]=L2014[objects].astype('int64') # convert all numerical values to integers\n",
    "L2014_filtered=L2014[L2014['Salary']<88888888] # remove records that do not have valid earnings values\n",
    "L2014_filtered.loc[:,'Year']=2014 # add year variable to identify data from different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "L2015=pd.read_csv(\"Labour/LMDSA 2015 v1.0 CSV.csv\")\n",
    "L2015=L2015[L2015['Q54a_monthly'].isna()==False] # remove records that do not have valid earnings values\n",
    "L2015=L2015[['Province','Q13GENDER','Q14AGE','Q16MARITALSTATUS','Q18FIELD',\\\n",
    "            'Q41MULTIPLEJOBS','occup','indus','Hrswrk','Q54a_monthly','Geo_type','sector1','Education_Status']]\n",
    "L2015.columns=labels\n",
    "L2015=L2015.fillna(88888888) # fill missing values with a dummy value\n",
    "objects=L2015.select_dtypes(include=['object']).columns\n",
    "L2015=L2015.replace('1.79769313486232e+308',88888888)\n",
    "L2015[objects]=L2015[objects].astype('int64') # convert all numerical values to integers\n",
    "L2015_filtered=L2015[L2015['Salary']<88888888] # remove records that do not have valid earnings values\n",
    "L2015_filtered.loc[:,'Year']=2015 # add year variable to identify data from different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2016=pd.read_csv(\"Labour/LMD!2016_F1.csv\")\n",
    "L2016=L2016[L2016['Q54a_monthly'].isna()==False] # remove records that do not have valid earnings values\n",
    "L2016=L2016[['Province','Q13GENDER','Q14AGE','Q16MARITALSTATUS','Q18FIELD',\\\n",
    "            'Q41MULTIPLEJOBS','occup','indus','Hrswrk','Q54a_monthly','Geo_type','sector1','Education_Status']]\n",
    "L2016.columns=labels\n",
    "L2016=L2016.fillna(88888888) # fill missing values with a dummy value\n",
    "objects=L2016.select_dtypes(include=['float64']).columns # convert all numerical values to integers\n",
    "L2016[objects]=L2016[objects].astype('int64')\n",
    "L2016_filtered=L2016[L2016['Salary']<88888888] # remove records that do not have valid earnings values\n",
    "L2016_filtered.loc[:,'Year']=2016 # add year variable to identify data from different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2017=pd.read_csv(\"Labour/LMD!2017_F1.csv\")\n",
    "L2017=L2017[L2017['Q54a_monthly'].isna()==False] # remove records that do not have valid earnings values\n",
    "L2017=L2017[['Province','Q13GENDER','Q14AGE','Q16MARITALSTATUS','Q18FIELD',\\\n",
    "            'Q41MULTIPLEJOBS','occup','indus','Q418HRSWRK','Q54a_monthly','Geo_type_code','sector1','Education_Status']]\n",
    "L2017.columns=labels\n",
    "L2017=L2017.fillna(88888888) # fill missing values with a dummy value\n",
    "objects=L2017.select_dtypes(include=['float64']).columns\n",
    "L2017[objects]=L2017[objects].astype('int64') # convert all numerical values to integers\n",
    "L2017_filtered=L2017[L2017['Salary']<88888888] # remove records that do not have valid earnings values\n",
    "L2017_filtered.loc[:,'Year']=2017 # add year variable to identify data from different years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all the data frames from the different years into one data frame\n",
    "L_All=pd.concat([L2013_filtered,L2014_filtered,L2015_filtered,L2016_filtered,L2017_filtered],join='inner',ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of records per year:')\n",
    "print('2013: {:}'.format(L2013_filtered.shape[0]))\n",
    "print('2014: {:}'.format(L2014_filtered.shape[0]))\n",
    "print('2015: {:}'.format(L2015_filtered.shape[0]))\n",
    "print('2016: {:}'.format(L2016_filtered.shape[0]))\n",
    "print('2017: {:}'.format(L2017_filtered.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Encode variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fact that most of the variables being considered in this project are categorical variables. The values of the categorical variables are numeric however the numbers have no real meaning beyond labelling the different categories. Therefore, the categorical variables need to be transformed into indicator variables using one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-categorical variables from the list that will be encoded\n",
    "labels.remove('Age')\n",
    "labels.remove('Salary')\n",
    "labels.remove('Hours_worked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2017_dummies = pd.get_dummies(L2017_filtered, columns = labels, drop_first = False)\n",
    "L2017_dummies=L2017_dummies.drop(['Study_field_88888888'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2016_dummies = pd.get_dummies(L2017_filtered, columns = labels, drop_first = False)\n",
    "L2016_dummies=L2016_dummies.drop(['Study_field_88888888'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2015_dummies = pd.get_dummies(L2015_filtered, columns = labels, drop_first = False)\n",
    "L2015_dummies=L2015_dummies.drop(['Study_field_88888888'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2014_dummies = pd.get_dummies(L2014_filtered, columns = labels, drop_first = False)\n",
    "L2014_dummies=L2014_dummies.drop(['Study_field_88888888'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2013_dummies = pd.get_dummies(L2013_filtered, columns = labels, drop_first = False)\n",
    "L2013_dummies=L2013_dummies.drop(['Study_field_88888888'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAll_dummies = pd.get_dummies(L_All, columns = labels, drop_first = False)\n",
    "LAll_dummies=LAll_dummies.drop(['Study_field_88888888','Geotype_88888888'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, to explore the relationship between gender and monthly earnings, the mean earnings for the different genders from the year 2013-2017 is plotted. As can be seen in the plot, the monthly earnings of women is consistently less than the monthly earnings for mean over this time period. This is in line with the findings of external sources (https://www.thesouthafrican.com/news/gender-pay-gap-south-africa-charts/  ). A violin plot for the different genders in the different years is also provided to investigate the distribution of the monthly earnings for the different genders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_palette(\"Reds\", n_colors=2)\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "L_All.groupby([\"Year\",\"Gender\"]).mean()['Salary'].unstack().plot(ax=ax) # group data by year and gender\n",
    "# rename labels in legend to names rather than integers\n",
    "plt.legend(['Male','Female'],fancybox=True,fontsize=15)\n",
    "plt.title('Mean monthly earnings per gender (2013-2017)',fontsize=20)\n",
    "plt.xticks(np.arange(2013, 2017, 1))  \n",
    "plt.xlabel('Year',fontsize=20)\n",
    "plt.ylabel('Mean earnings',fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_mod_2 = L_All.loc[L_All.Salary < 10000]\n",
    "sns.set()\n",
    "sns.set_palette(\"Reds\", n_colors=2)\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.catplot(x='Year', y='Salary', kind=\"violin\",split=True, data=L_mod_2, hue='Gender',ax=ax)\n",
    "plt.close()\n",
    "plt.title('Distribution of monthly earnings per gender (2013-2017)',fontsize=20) \n",
    "plt.xlabel('Year',fontsize=20)\n",
    "plt.ylabel('Monthly earnings',fontsize=20)\n",
    "# plt.legend(['Male','Female'],fancybox=True,fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The violin plot shows the distribution of monthly earnings around the mean for the different genders in the different years. It is shown that for all the years, the distributions for both genders remain similar as the the monthly earnings is negatively skewed, with most of the observations occuring on the lower end of the scale. The mode is less than the mean for both genders, leading to the skewed distribution. However, the monthly salary for women is more highly negatively skewed, which is also indicated by the lower mean monthly earnings shown for women. Therefore, there are more women that have monthly earnings that reported at the lower end of the scale than men, leading to a lower mean monthly salary. However, included in the scope of this project is to investigate other factors that may also be related to the monthly earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix between monthly earnings and different categories of occupations\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "corr_df=LAll_dummies[['Salary','Occupation_1','Occupation_2','Occupation_3','Occupation_4',\\\n",
    "                     'Occupation_5','Occupation_6','Occupation_7','Occupation_8','Occupation_9',\\\n",
    "                     'Occupation_10','Occupation_11']].corr(method='pearson')\n",
    "mask=np.zeros_like(corr_df)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "sns.heatmap(corr_df,cmap='RdYlGn_r',vmax=1.0,vmin=-1.0,mask=mask,linewidths=2.5,ax=ax)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot correlation matrix between monthly earnings and different categories of education status\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "corr_df=LAll_dummies[['Salary','Edu_status_1','Edu_status_2','Edu_status_3','Edu_status_4',\\\n",
    "                     'Edu_status_5','Edu_status_6']].corr(method='pearson')\n",
    "mask=np.zeros_like(corr_df)\n",
    "mask[np.triu_indices_from(mask)]=True\n",
    "sns.heatmap(corr_df,cmap='RdYlGn_r',vmax=1.0,vmin=-1.0,mask=mask,linewidths=2.5,ax=ax)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation plots indicate that there is also relationships between monthly earnings and education status as well as monthly earnings and occupation. There appears to be a positive correlation between monthly earnings and Edu_status_6 (Tertiary education) as well as between Occupation_2 (Professional) and monthly earnings. However, the relationship between monthly earnings and the various variables of interest cannot only be considered in isolation, as the interations between indicator variables may also affect the relationship. Therefore correlation of individual features with the response variable is not enough. In the following section, the features will be used to fit a OLS model to investigate the relationships between the features and the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initial modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the data is fit to OLS regression models to do some preliminary investigation into the features that relate to monthly earnings. Firstly, the relationship between monthly earnings and gender needs to be investigated. To do this, the gender data alone is used to fit a OLS regression model for monthly earnings. Since there is collinearity between the two encoded gender variables, the condition number is very high, so it is not a good model. However, the coefficients show that Gender_1 contributes more to higher earnings rather than Gender_2 which is also shown by the mean monthly earnings of men and women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"Salary ~ Gender_1 + Gender_2\"\n",
    "gender2017_model = smf.ols(formula, L2017_dummies).fit(fit_intercept=False)\n",
    "print(gender2017_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is necessary to look at a model fit using all the variables included in the dataset. While the R-squared and R-squared adjusted values for this model is much higher, there are still many issues. The condition number is very high which indicates a problem with multicollinearity. The confidence intervals for many of the variables are very wide and many include 0, which indicates that the quality of the model is bad. The AIC score is also high since so many variables are used. Therefore, significant features need to be selected and the model refit before any conclusions can be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2017_without_response=L2017_dummies.drop(['Salary','Year'],axis=1)\n",
    "response='Salary'\n",
    "formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(L2017_without_response.columns))\n",
    "all2017_model = smf.ols(formula, L2017_dummies).fit(fit_intercept=False)\n",
    "print(all2017_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the procedures used to select the features used for the model are discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this project investigates whether other factors are also related to monthly earnings, the factors to be included in the model need to be chosen. In order to do this, step-wise regression is used. This is done in 3 parts:<br/>\n",
    "\n",
    "1) In order to reduce multicollinearity problems in the data, the Variance Inflation Factors (VIFs) are calculated and the variables with a VIF above a certain threshold are excluded from the variables included in the model.\n",
    "\n",
    "2) forward-backward feature selection based on p-value from statsmodels.api.OLS is performed to select the most significant features to include in the final model <br/>\n",
    "\n",
    "3) forward selection is used with the selected features to fit the the optimal model evaluated by the adjusted R-squared value <br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Variable Inflation Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the VIFs are calculated and the variables that exhibit a high degree of multicollinearity are excluded from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vif_(X, thresh=10):\n",
    "    \"\"\"Calculation of VIFs to reduce multicollinearity problems.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : pandas DataFrame with all possible predictors and\n",
    "    without the response variable\n",
    "\n",
    "    thresh: integer, threshold by which to exclude variables\n",
    "    for dataset\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    remaining: list of variable names that still remain in \n",
    "               the dataset\n",
    "\n",
    "    \"\"\"\n",
    "    cols = X.columns\n",
    "    variables = np.arange(X.shape[1])\n",
    "    dropped=True\n",
    "    while dropped:\n",
    "        dropped=False\n",
    "        c = X[cols[variables]].values\n",
    "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
    "\n",
    "        maxloc = vif.index(max(vif))\n",
    "        if max(vif) > thresh:\n",
    "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
    "            variables = np.delete(variables, maxloc)\n",
    "            dropped=True\n",
    "\n",
    "#     print('Remaining variables:')\n",
    "#     print(X.columns[variables])\n",
    "    remaining=cols[variables]\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_inflated_variables(data,sample_size,print_out=True):\n",
    "    \"\"\"Calculation of VIFs to reduce multicollinearity problems\n",
    "    using a subset of the data\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and\n",
    "    the response variable\n",
    "\n",
    "    sample_size: integer, size of the sample used to estimate the\n",
    "    VIFs\n",
    "    \n",
    "    print_out : whether to print the sequence of exclusions\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    remaining: list of variable names that still remain in \n",
    "               the dataset\n",
    "\n",
    "    \"\"\"\n",
    "    sample_train=resample(data,n_samples=sample_size)\n",
    "    sample_dummy_mod = sample_train.drop(['Salary','Year'], axis = 1)\n",
    "    remaining=calculate_vif_(sample_dummy_mod)\n",
    "    return remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'L2017_dummies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cea6bd2a940e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mremaining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremove_inflated_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL2017_dummies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'L2017_dummies' is not defined"
     ]
    }
   ],
   "source": [
    "remaining=remove_inflated_variables(L2017_dummies,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the output above it can be seen that the highly correlated features are removed, particularly the first dummy variable from most of the feature as it provides redundant information. However, this is not true for the Study field feature as there are so many categories that none of the dummy variables exhibit collinearity with the other dummy variables. Edu_status_6 indicates tertiary education and will exhibit high collinearity with the study field dummy variables since the study field dummy variables are only applicable if the person has obtained some level of tertiary education."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Forward-backward feature selection based on p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the most significant features based on p-values is selected. An OLS regresion model is fit iteratively by adding variables in the formula and adding the variable with the lowest p-value to the inclusion list. This is the forward step part of the algorithm. For the backward step, the OLS is fitted using all the included features, and the feature with the highest p value is selected. If the p value is higher than the threshold (0.05), the feature is excluded from the selected feature list. In this way, the most significant features are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepwise_selection(X, y, \n",
    "                       initial_list=[], \n",
    "                       threshold_in=0.001, \n",
    "                       threshold_out = 0.05, \n",
    "                       verbose=True):\n",
    "    \"\"\" Perform a forward-backward feature selection \n",
    "    based on p-value from statsmodels.api.OLS\n",
    "    Parameters:\n",
    "        X - pandas.DataFrame with candidate features\n",
    "        y - list-like with the target\n",
    "        initial_list - list of features to start with (column names of X)\n",
    "        threshold_in - include a feature if its p-value < threshold_in\n",
    "        threshold_out - exclude a feature if its p-value > threshold_out\n",
    "        verbose - whether to print the sequence of inclusions and exclusions\n",
    "    Returns: list of selected features \n",
    "    \"\"\"\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        # forward step\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "            if verbose:\n",
    "                print('Add  {:30} with p-value {:.6}'.format(best_feature, best_pval))\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            if verbose:\n",
    "                print('Drop {:30} with p-value {:.6}'.format(worst_feature, worst_pval))\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train=resample(L2017_dummies,n_samples=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_train[remaining]\n",
    "y = sample_train['Salary']\n",
    "result = stepwise_selection(X, y, print_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the step-wise selection of features based on their p value is shown above. It is shown that even if a feature was significant in one model, that the same is not necessarily true for other models in the case of Occupation_2 (Professional). A feature may be viewed as less significant when other features are added therefore it is important to consider the iterations of the features in different models, rather than individual p values or correlation.\n",
    "\n",
    "Most of the significant features are related to the occupation of the respondent, while some features relating to their field of study, province, marital status and gender also prove to be significant. In the next section, these feature will be used with forward selection to fit the \"optimal\" regression model, and see if this model is an improvement over the model where all possible features are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Foward selection for the optimal model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the optimal model is fit using the selected features and forward selection. OLS models are fit by iteratively adding candidate features to the formula used to fit the regression model. The model is then evaluated using the adjusted R-squared score, and the candidate with the associated R-squared adjusted score is appended to a list. The candidates with the best scores are then added to the formula and the resulting model is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    \"\"\"Linear model designed by forward selection.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and response\n",
    "\n",
    "    response: string, name of response column in data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model: an \"optimal\" fitted statsmodels linear model\n",
    "           with an intercept\n",
    "           selected by forward selection\n",
    "           evaluated by adjusted R-squared\n",
    "    \"\"\"\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    count=0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "#             print('Candidate: {:}'.format(candidate))\n",
    "            formula = \"{} ~ {} + 1\".format(response,\n",
    "                                           ' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit(fit_intercept=False).rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        count+=1\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if ((current_score < best_new_score) or (count>=20)):\n",
    "            print('Adding: {}'.format(best_candidate))\n",
    "            count=0\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit(fit_intercept=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.append('Salary')\n",
    "model=forward_selected(sample_train[result], 'Salary',print_out=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all the features that where selected as significant based on their p value are necessarily included in the feature list for the optimal model. This is because the the p value is not the only important metric to establish whether the inclusion of the feature will improve the regression model. The interactions between different features are also important to establish the relationships between the response variable and the candidate variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the summary output above, the performance of the model is much improved over the performance of the regression model using all the possible features. The condition number is much lower, indicating that there is no longer a problem with multicollinearity. This is expected, as the calculation of the VIFs was used to remove features that showed high levels of multicollinearity. \n",
    "\n",
    "The adjusted R-squared value is higher, indicating that more of the variation in the monthly earnings variable is explained by the features used to fit the regression model. The gap between the R-squared and adjusted R-squared is also not wide, indicating that there are not many unnecessary features included that have biased the R-squared value.\n",
    "\n",
    "The standard error for the features are much lower, indicating that the feature is now a much more accurate representation of the actual population. The width of the confidence intervals are much smaller, indicating that the regression coefficient is now a much more accurate representation of the relationship between the features and monthly earnings.\n",
    "\n",
    "Therefore the procedure has worked to produce a better quality model that can be used to evaluate the relationships between monthly earnings and the other variables. In the next section, the resampling technique of bootstrapping is applied to test the models produced by this procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Bootstrapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an inference task, bootstrapping can be used for in-sample resampling. Bootstrapping is used in two ways for this project. Bootstrapping is firstly used to determine the best features for our final model, using a resampling procedure. For each bootstrap sample, the step-wise regression process is performed and the selected feature for that sample is saved. The features that are selected for at least a specific fraction of the iterations are used in the final model. Bootstrapping is then used to create a distribution of the regression coefficients and to calculate the confidence intervals for each coefficient. These coefficients will be used to analyse the relations between the candidate variables and monthly earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrapping(data,iters,sample_size):\n",
    "    \"\"\"Use random sampling to collect the features that are most often\n",
    "    used for the optimal regression model \n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas DataFrame with all possible predictors and\n",
    "    the response variable\n",
    "    \n",
    "    iters : integer, the number of samples that must be taken\n",
    "    from the data\n",
    "\n",
    "    sample_size: integer, size of the sample used to fit the\n",
    "    regression model\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    resulting_models: list of the models and model parameters fit \n",
    "    for each sample\n",
    "\n",
    "    \"\"\"\n",
    "    resulting_models=[]\n",
    "    imp=remove_inflated_variables(data,sample_size)\n",
    "    for i in range(0,iters):\n",
    "        clear_output(wait=True)\n",
    "        print('Starting iteration: {:}'.format(i))\n",
    "        sample_train=resample(data,n_samples=sample_size)\n",
    "        X = sample_train[imp]\n",
    "        y=sample_train['Salary']\n",
    "        result = stepwise_selection(X, y,verbose=False)\n",
    "        result.append('Salary')\n",
    "        model=forward_selected(sample_train[result], 'Salary')\n",
    "        parameters=[]\n",
    "        parameters=[model,model.params,model.bse,model.pvalues,model.conf_int(),model.condition_number,model.rsquared_adj]\n",
    "        resulting_models.append(parameters)\n",
    "        print('Finish iteration: {:}'.format(i))\n",
    "    return resulting_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L2017_models=bootstrapping(L2017_dummies,50,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_features(model_list,tol,iters_fraction):\n",
    "    \"\"\"Use model list obtained from resampling procedure and \n",
    "    select the features that were used in the best models\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    model_list : list of the models and model parameters fit \n",
    "    for each sample\n",
    "\n",
    "    tol: float, the threshold value for the R-squared adjusted \n",
    "    value for a model to be included in feature list\n",
    "    \n",
    "    iters_fraction : integer, minimum number of models in which a \n",
    "    feature must be included for it to be included in the feature \n",
    "    list\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    valid: list of the features that meet all the necessary\n",
    "    criteria to be included in the final model\n",
    "\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for i in range(len(model_list)):\n",
    "        if (model_list[i][6]>tol):\n",
    "            feat=list(model_list[i][1].index)\n",
    "            for f in feat:\n",
    "                try:\n",
    "                    features[f]+=1\n",
    "                except:\n",
    "                    features[f]=1\n",
    "    valid=[]\n",
    "    for feat,value in features.items():\n",
    "        if ((value>=iters_half) and (feat!='Intercept')):\n",
    "            valid.append(feat)\n",
    "#         valid=valid[1:]\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid=get_most_common_features(L2017_models,0.15,17)\n",
    "valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features selected using the step-wise regression procedure in conjuction with the resampling procedure of bootstrapping has produced a list of features that have most often been included in the best performing models. This list incudes less features than the previous model fit with selected features. We will now evaluate the performance of a model fit using these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response='Salary'\n",
    "formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(valid))\n",
    "sample_dummy_mod = L2017_dummies.drop(['Year'], axis = 1)\n",
    "model = smf.ols(formula, sample_dummy_mod).fit(fit_interept=False)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The condition number is low indicating that there is no problem with multicollinearity. There is no gap between the R-squared value and the adjusted R-squared value, indicating that there is no redundant feature included in this model that makes no change to the performance of the model, therefore every feature has value in this regression. The width of the confidence intervals for certain variables (e.g. Study_field_8) is smaller, indicating higher probability that the regression coeffiecient is accurate. The p value of the F-test is below the threshold (0.05), indicating that there is enough evidence to reject the null hypothesis and that the joint effect of these variables are statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resulting_coefficients(valid,data,sample_size,iters):\n",
    "    \"\"\"Fit the regression models using the selected features\n",
    "    and samples from the data to get a distribution of the regression \n",
    "    coefficients for the different features\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    valid: list of the features that meet all the necessary\n",
    "    criteria to be included in the final model\n",
    "\n",
    "    data : pandas DataFrame with all possible predictors and\n",
    "    the response variable\n",
    "    \n",
    "    sample_size: integer, size of the sample used to fit the\n",
    "    regression model\n",
    "    \n",
    "    iters : integer, the number of samples that must be taken\n",
    "    from the data\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    resulting_coefficients: list of regression coeffient values for each \n",
    "    feature obtained from each model fit with each sample\n",
    "\n",
    "    \"\"\"\n",
    "    response='Salary'\n",
    "    formula = \"{} ~ {} + 1\".format(response,\n",
    "                                   ' + '.join(valid))\n",
    "    resulting_coefficients=[]\n",
    "    for i in range(0,iters):\n",
    "        sample_train=resample(data,n_samples=sample_size)\n",
    "        sample_dummy_mod = sample_train.drop(['Year'], axis = 1)\n",
    "        model = smf.ols(formula, sample_dummy_mod).fit()\n",
    "        resulting_coefficients.append([model.params,model.bse,model.conf_int()])\n",
    "    return resulting_coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to test the model and features obtained by the previous procedure, resampling will be used to get a distribution of the regression coefficients for each of the selected features. The mean of this distribution is then calculated and this value is used to identify the relationship between the variables and monthly earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs=get_resulting_coefficients(valid,L2017_dummies,5000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_intervals(coefficients_list,valid):\n",
    "    \"\"\"Get the mean and confidence intervals for the regression coefficients\n",
    "    of each feature\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    coefficients: list of regression coeffient values for each \n",
    "    feature obtained from each model fit with each sample\n",
    "\n",
    "    valid : list of the features that meet all the necessary\n",
    "    criteria to be included in the final model\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    mean_conf_intv: mean and confidence intervals for each feature\n",
    "    in selected feature list\n",
    "    \"\"\"\n",
    "    ranges=[]\n",
    "    for i in range(1,len(valid)+1):\n",
    "        coeffs_param=[]\n",
    "        for j in range(0,len(coefficients_list)):\n",
    "            coeffs_param.append(coefficients_list[j][0][i])\n",
    "        ranges.append(coeffs_param)\n",
    "    mean_conf_intv=[]\n",
    "    for k in range(0,len(valid)):\n",
    "        test=np.array(ranges[k])\n",
    "        mean_param=test.mean()\n",
    "        test.sort()\n",
    "        conf_intv=np.percentile(test,[2.5,97.5])\n",
    "        mean_conf_intv.append([mean_param,conf_intv])\n",
    "    return mean_conf_intv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_intv=get_conf_intervals(coefs,valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(valid)):\n",
    "    print('Feature: {}'.format(valid[i]))\n",
    "    print('mean coefficient: {}'.format(conf_intv[i][0]))\n",
    "    print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that there is a relationship between occupation and monthly earnings. However, the type of occupation has a different effect on monthly earnings. Occupation_2 indicates that the person works as professional, and the relationship to monthly earnings is positive, indicating that working as a professional has a positive relationship to monthly earning and is probably associated with higher monthly earnings if considered independently from the other features. Other occupations such as Occupation_9 and Occupation_10 (Elementary Occupation and Domestic workers) have a negative relationship with monthly earnings, indicating that working in these fields are often associated with lower monthly earnings. \n",
    "\n",
    "There is a relationship between a person's location and monthly earnings, however only in Province_7 (Gauteng) where there is a positive relationship with monthly earnings, indicating that people in Gauteng may earn higher monthly wages, when considered in isolation from the other features.\n",
    "\n",
    "The only field of study that is significantly related to monthly earnings is Engineering. There is a positive relationship between this study field and monthly earnings, therefore when considered in isolation, studying in this field may lead to higher monthly earnings according to this model.\n",
    "\n",
    "If a person has never been married is negatively related to monthly earnings. There is a significant relationship between gender and monthly earnings. It is worth noting that there is a negative relationship between being a woman and monthly earnings.\n",
    "\n",
    "Now that the relationships between monthly earnings and the other variables have been analysed for the year 2017, we will consider these relationships over the period of 2013-2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Change in coefficients over the years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we consider how the values of the regression coefficients have changed over the period of 2013-2017. In order to do this, the resampling procedure described in the previous section is used with the data from each year and the selected features from all years are collected. The coefficients for these selected features are then calculated and the mean coefficients for each feature for every year is plotted to see the changes that occur over the period of 2013-2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model fitted for each sample using the resampling technique\n",
    "L2017_models=bootstrapping(L2017_dummies,100,5000)\n",
    "L2016_models=bootstrapping(L2016_dummies,100,5000)\n",
    "L2015_models=bootstrapping(L2015_dummies,100,5000)\n",
    "L2014_models=bootstrapping(L2014_dummies,100,5000)\n",
    "L2013_models=bootstrapping(L2013_dummies,100,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_r_squared(model_list):\n",
    "    \"\"\"Get the mean adjusted R-squared value to establish a baseline\n",
    "    by which the models are compared\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    coefficients: list of regression coeffient values for each \n",
    "    feature obtained from each model fit with each sample\n",
    "\n",
    "    model_list : list of the models and model parameters fit \n",
    "    for each sample\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    means: mean adjusted R-squared value for all the models\n",
    "    in the model list\n",
    "    \"\"\"\n",
    "    r_squared=[]\n",
    "    for i in range(0,len(model_list)):\n",
    "        r_squared.append(model_list[i][6])\n",
    "    means=np.array(r_squared).mean()\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most common features included in the regression model for each year\n",
    "valid2017=get_most_common_features(L2017_models,get_mean_r_squared(L2017_models),34)\n",
    "valid2016=get_most_common_features(L2016_models,get_mean_r_squared(L2016_models),34)\n",
    "valid2015=get_most_common_features(L2015_models,get_mean_r_squared(L2015_models),34)\n",
    "valid2014=get_most_common_features(L2014_models,get_mean_r_squared(L2014_models),34)\n",
    "valid2013=get_most_common_features(L2013_models,get_mean_r_squared(L2013_models),34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Selected features for each year:')\n",
    "print(\"--------------------------------\")\n",
    "print('2013: {:}'.format(valid2013))\n",
    "print('2014: {:}'.format(valid2014))\n",
    "print('2015: {:}'.format(valid2015))\n",
    "print('2016: {:}'.format(valid2016))\n",
    "print('2017: {:}'.format(valid2017))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen by the above output, the same features were not selected for each year, indicating that the relationships between the features and the response variable differ each year. Certain features such as Occupation_9 and Occupation_10 (Elementary occupation and Domestic worker) are consistently related to monthly earnings while gender is only included once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist=valid2017+valid2016+valid2015+valid2014+valid2013\n",
    "valid_all=list(set(mylist))\n",
    "valid_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above represents the most commonly occurring features for all the models over all the years. The regression coefficients for these features for the different years will now be calculated to show how the coefficients differ over the period of 2013-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs2017=get_resulting_coefficients(valid_all,L2017_dummies,5000,1000)\n",
    "coefs2016=get_resulting_coefficients(valid_all,L2016_dummies,5000,1000)\n",
    "coefs2015=get_resulting_coefficients(valid_all,L2015_dummies,5000,1000)\n",
    "coefs2014=get_resulting_coefficients(valid_all,L2014_dummies,5000,1000)\n",
    "coefs2013=get_resulting_coefficients(valid_all,L2013_dummies,5000,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_conf_intervals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a22afbcd77dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconf_intv2017\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_conf_intervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs2017\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconf_intv2016\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_conf_intervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs2016\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mconf_intv2015\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_conf_intervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs2015\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconf_intv2014\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_conf_intervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs2014\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconf_intv2013\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_conf_intervals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoefs2013\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_conf_intervals' is not defined"
     ]
    }
   ],
   "source": [
    "conf_intv2017=get_conf_intervals(coefs2017,valid_all)\n",
    "conf_intv2016=get_conf_intervals(coefs2016,valid_all)\n",
    "conf_intv2015=get_conf_intervals(coefs2015,valid_all)\n",
    "conf_intv2014=get_conf_intervals(coefs2014,valid_all)\n",
    "conf_intv2013=get_conf_intervals(coefs2013,valid_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the coefficient data in to a form that can be easily plotted\n",
    "years=[2013,2014,2015,2016,2017]\n",
    "conf_ints=[conf_intv2013,conf_intv2014,conf_intv2015,conf_intv2016,conf_intv2017]\n",
    "temps=[]\n",
    "for i in range(0,len(valid_all)):\n",
    "    temp=[]\n",
    "    for j in range(0,5):\n",
    "        temp_conf_int=conf_ints[j][i][0]\n",
    "        temp.append(temp_conf_int)\n",
    "    temps.append(temp)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the values of the coefficents for the most common features over the period of (2013-2017)\n",
    "sns.set()\n",
    "ax=plt.figure(figsize=(20,50))\n",
    "cmap = plt.get_cmap('Paired')\n",
    "for i in range(0,len(valid_all)):\n",
    "    plt.subplot(len(valid_all),1,i+1)\n",
    "    plt.plot(years,temps[i],c=cmap(i))\n",
    "    plt.xticks(np.arange(2013, 2017, 1)) \n",
    "    name=valid_all[i]\n",
    "    plt.title(name,fontsize=15)\n",
    "    plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the plots above, the regression coefficients of the features do not remain constant over the years, indicating that the relationship of the feature to monthly earnings as well as the other features differ over the years. It is worth noting that over this period, certain features have maintained a exclusively negative/positive relationship with monthly earnings, while the relationship of other features changed the nature of the relationship from negative to positive and vice versa. This indicates that the same features do not have the same relationship or significance to monthly earnings over this period of time. Therefore, the results from one year can not necessarily be generalised to the entire time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer to research question\n",
    "\n",
    "The tests above have shown that there is a joint relationship between the education, work and location of a person as well as the gender of the person to the monthly earnings they earn in South Africa. While gender may be related to monthly earnings, gender alone is not enough to infer the monthly earnings of a person, factors such as their level of education and occupation must also be considered.\n",
    "\n",
    "#### Short comings\n",
    "\n",
    "The data used in this investigation is not representative of the entire population of South Africa, therefore the results of this project can not necessarily be generalised to the entire population. If a more representative sample of data from the South African workforce is obtained, the results may be more representative of the entire South African population.\n",
    "\n",
    "#### Future considerations\n",
    "\n",
    "The purpose of this project was only to identify the existence of relationships between the variables of interest and monthly earnings. However, the project can be extended to describe the possible causal relationships that exist between the variables. This project can be extended to improve the performance of the models fit using the features of interest, with the use of more sophisticated feature selection techniques and regression modelling techniques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
