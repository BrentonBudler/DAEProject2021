{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#3.1-Data-Description\" data-toc-modified-id=\"3.1-Data-Description-1\">3.1 Data Description</a></span></li><li><span><a href=\"#3.2-Data-Ingestion\" data-toc-modified-id=\"3.2-Data-Ingestion-2\">3.2 Data Ingestion</a></span></li><li><span><a href=\"#3.3-Data-Wrangling-and-Data-Cleaning\" data-toc-modified-id=\"3.3-Data-Wrangling-and-Data-Cleaning-3\">3.3 Data Wrangling and Data Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.3.1-Wrangling-and-Cleaning-of-Employment-Data\" data-toc-modified-id=\"3.3.1-Wrangling-and-Cleaning-of-Employment-Data-3.1\">3.3.1 Wrangling and Cleaning of Employment Data</a></span></li><li><span><a href=\"#3.3.2-Wrangling-and-Cleaning-of-Household-Income-Data\" data-toc-modified-id=\"3.3.2-Wrangling-and-Cleaning-of-Household-Income-Data-3.2\">3.3.2 Wrangling and Cleaning of Household Income Data</a></span></li><li><span><a href=\"#3.3.3-Wrangling-and-Cleaning-of-Grant-Data\" data-toc-modified-id=\"3.3.3-Wrangling-and-Cleaning-of-Grant-Data-3.3\">3.3.3 Wrangling and Cleaning of Grant Data</a></span></li></ul></li><li><span><a href=\"#3.4-Data-Exploration-and-Analysis\" data-toc-modified-id=\"3.4-Data-Exploration-and-Analysis-4\">3.4 Data Exploration and Analysis</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.4.1-Exploration-and-Analysis-of-UIF-and-Other-Grants-in-April\" data-toc-modified-id=\"3.4.1-Exploration-and-Analysis-of-UIF-and-Other-Grants-in-April-4.1\">3.4.1 Exploration and Analysis of UIF and Other Grants in April</a></span></li><li><span><a href=\"#3.4.1-Exploration-and-Analysis-of-Household-Income-in-April\" data-toc-modified-id=\"3.4.1-Exploration-and-Analysis-of-Household-Income-in-April-4.2\">3.4.1 Exploration and Analysis of Household Income in April</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinoanasta/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (6,121,151) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>w1_nc_outcome</th>\n",
       "      <th>w1_nc_intrv_c</th>\n",
       "      <th>w1_nc_intrv_d</th>\n",
       "      <th>w1_nc_intrv_m</th>\n",
       "      <th>w1_nc_intrv_y</th>\n",
       "      <th>w1_nc_duration</th>\n",
       "      <th>w1_nc_dob_m</th>\n",
       "      <th>w1_nc_dob_y</th>\n",
       "      <th>w1_nc_gen</th>\n",
       "      <th>...</th>\n",
       "      <th>w1_nc_intlng2</th>\n",
       "      <th>w1_nc_intlng3</th>\n",
       "      <th>w1_nc_intlng4</th>\n",
       "      <th>w1_nc_intlng5</th>\n",
       "      <th>w1_nc_intlng6</th>\n",
       "      <th>w1_nc_intlng7</th>\n",
       "      <th>w1_nc_intlng8</th>\n",
       "      <th>w1_nc_intlng9</th>\n",
       "      <th>w1_nc_intlng10</th>\n",
       "      <th>w1_nc_intlng11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>301013</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>610</td>\n",
       "      <td>15th</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "      <td>15.95</td>\n",
       "      <td>June</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>Man</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301058</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>611</td>\n",
       "      <td>25th</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "      <td>22.03</td>\n",
       "      <td>January</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>301059</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>604</td>\n",
       "      <td>20th</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "      <td>12.75</td>\n",
       "      <td>July</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>301062</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>640</td>\n",
       "      <td>25th</td>\n",
       "      <td>June</td>\n",
       "      <td>2020</td>\n",
       "      <td>22.33</td>\n",
       "      <td>June</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>...</td>\n",
       "      <td>English</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301067</td>\n",
       "      <td>Successfully Interviewed</td>\n",
       "      <td>609</td>\n",
       "      <td>15th</td>\n",
       "      <td>May</td>\n",
       "      <td>2020</td>\n",
       "      <td>15.2</td>\n",
       "      <td>July</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>Woman</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pid             w1_nc_outcome  w1_nc_intrv_c w1_nc_intrv_d  \\\n",
       "0  301013  Successfully Interviewed            610          15th   \n",
       "1  301058  Successfully Interviewed            611          25th   \n",
       "2  301059  Successfully Interviewed            604          20th   \n",
       "3  301062  Successfully Interviewed            640          25th   \n",
       "4  301067  Successfully Interviewed            609          15th   \n",
       "\n",
       "  w1_nc_intrv_m  w1_nc_intrv_y w1_nc_duration w1_nc_dob_m w1_nc_dob_y  \\\n",
       "0          June           2020          15.95        June      1981.0   \n",
       "1          June           2020          22.03     January      1948.0   \n",
       "2          June           2020          12.75        July      1990.0   \n",
       "3          June           2020          22.33        June      1972.0   \n",
       "4           May           2020           15.2        July      1971.0   \n",
       "\n",
       "  w1_nc_gen  ... w1_nc_intlng2 w1_nc_intlng3 w1_nc_intlng4 w1_nc_intlng5  \\\n",
       "0       Man  ...           NaN           NaN           NaN           NaN   \n",
       "1     Woman  ...           NaN           NaN           NaN           NaN   \n",
       "2     Woman  ...           NaN           NaN           NaN           NaN   \n",
       "3     Woman  ...       English           NaN           NaN           NaN   \n",
       "4     Woman  ...           NaN           NaN           NaN           NaN   \n",
       "\n",
       "  w1_nc_intlng6 w1_nc_intlng7 w1_nc_intlng8 w1_nc_intlng9 w1_nc_intlng10  \\\n",
       "0           NaN           NaN           NaN           NaN            NaN   \n",
       "1           NaN           NaN           NaN           NaN            NaN   \n",
       "2           NaN           NaN           NaN           NaN            NaN   \n",
       "3           NaN           NaN           NaN           NaN            NaN   \n",
       "4           NaN           NaN           NaN           NaN            NaN   \n",
       "\n",
       "  w1_nc_intlng11  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv('../Wave1.csv')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Social Welfare <a class=\"anchor\" id=\"chapter2_labour\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Covid-19 pandemic has had a negative impact on the South African economy. Consequently, many people had lost their jobs during the initial stages of the pandemic as seen in the Labour section. This section aims to determine the extent to which the South African government intervened in the economy to aid and assist those who had lost their jobs and livelihoods.\n",
    "\n",
    "Included in this section is a data description of the variables explored, an explanation of the initialization of a subset of the dataset, an explanation of the data cleaning and data wrangling methodology, as well as an exploratory analysis of the variables concerned. This exploratory analysis will investigate the relevant social welfare variables in the dataset (ie: all variables concerning household income and social grants) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Data Description \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the month of April 2020, participants in the survey were asked many questions regarding the impact that the Covid-19 pandemic had had on their lives. The variables that are analysed in this section correspond to the questions in the survey that relate to social welfare. \n",
    "\n",
    "**Employment in April**\n",
    "*  **job_in_apr'** : Did you have any kind of job in April?\n",
    "* **'work_in_apr'** : Did you work for profit/pay even just for an hour or a small amount in April?\n",
    "\n",
    "**UIF and Other Grants in April**\n",
    "* **uif_in_apr** : Did you receive the UIF reduced work time benefit in April?\n",
    "* **grant_from_gov_ques** : Did you receive any kind of grant from the government in April?\n",
    "* **grant_from_gov** : If you did receive a grant from the government in April, what kind of grant did you receive? \n",
    "<br><br>\n",
    "\n",
    "**Household Income in April** \n",
    "* **src_income_before_apr** : What was your household's main source of income before lockdown started on 27 March 2020?\n",
    "* **lost_income_in_apr** : Has your household lost its main source of income since the lockdown started on 27 March 2020?\n",
    "* **total_income_in_apr** : What was your household's total income after tax in April?\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this subsection, a subset of the raw dataframe is generated. This subset stores all of the relevant variables concerning social welfare in the raw dataframe. In addition, all of the variables in this subset have been appropriately renamed. For example, the variable named **w1_nc_hhinc** corresponding to the survery question, \"What was your household's total income after tax in April?\" in the raw dataframe was renamed to **total_income_in_apr**. Now, one can easily determine the meaning of the variable and the type of data it stores from first glance, instead of having to compare it with the key available on www.datafirst.uct.ac.za. \n",
    "\n",
    "Another measure implemented during this data ingestion phase was the appending of columns. In the raw dataframe the variables corresponding to the questions \"Did you receive any kind of grant from the government in April?\" and \"What was your household's main source of income before lockdown started on 27 March 2020?\" were split into 3 columns. The reason for this was not made clear. For improved readability and efficiency those columns were appended using the **append(pd.Series, ignore_index=True)** function to make them into one column. This appendage did not affect the data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "swdf = pd.DataFrame()\n",
    "\n",
    "# Employment in April Data\n",
    "swdf['job_in_apr'] = raw_data['w1_nc_em_apr']\n",
    "swdf['work_in_apr'] = raw_data['w1_nc_emany_apr']\n",
    "\n",
    "# Household Income in April - Here 3 columns are appended\n",
    "income1 = raw_data['w1_nc_hhincsrc1']; income2 = raw_data['w1_nc_hhincsrc2'];  income3 = raw_data['w1_nc_hhincsrc3']; \n",
    "income = income1.append(income2, ignore_index=True).append(income3, ignore_index=True)\n",
    "\n",
    "swdf['src_income_before_apr'] = income\n",
    "swdf['lost_income_in_apr'] = raw_data['w1_nc_hhincchng']\n",
    "swdf['total_income_in_apr'] = raw_data['w1_nc_hhinc']\n",
    "\n",
    "# UIF and Other Grants in April - Here 3 columns are appended\n",
    "swdf['uif_in_apr'] = raw_data['w1_nc_uneminc_uif']\n",
    "swdf['grant_from_gov_ques'] = raw_data['w1_nc_incgov']\n",
    "\n",
    "grant1 = raw_data['w1_nc_incgovtyp1']; grant2 = raw_data['w1_nc_incgovtyp2']; grant3 = raw_data['w1_nc_incgovtyp3']; \n",
    "grant = grant1.append(grant2, ignore_index=True).append(grant3, ignore_index=True)\n",
    "\n",
    "swdf['grant_from_gov'] = grant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the social welfare dataframe, appropriately named swdf, looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_in_apr</th>\n",
       "      <th>work_in_apr</th>\n",
       "      <th>src_income_before_apr</th>\n",
       "      <th>lost_income_in_apr</th>\n",
       "      <th>total_income_in_apr</th>\n",
       "      <th>uif_in_apr</th>\n",
       "      <th>grant_from_gov_ques</th>\n",
       "      <th>grant_from_gov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Income from a business</td>\n",
       "      <td>No</td>\n",
       "      <td>Don't Know</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Disability Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Government grants</td>\n",
       "      <td>No</td>\n",
       "      <td>3500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Old Age Pension Grant (OAP)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Government grants</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Child Support Grant (CSG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Government grants</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Child Support Grant (CSG)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Government grants</td>\n",
       "      <td>No</td>\n",
       "      <td>Don't Know</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  job_in_apr work_in_apr   src_income_before_apr lost_income_in_apr  \\\n",
       "0         No          No  Income from a business                 No   \n",
       "1        NaN         NaN       Government grants                 No   \n",
       "2         No          No       Government grants                Yes   \n",
       "3         No          No       Government grants                Yes   \n",
       "4         No          No       Government grants                 No   \n",
       "\n",
       "  total_income_in_apr uif_in_apr grant_from_gov_ques  \\\n",
       "0          Don't Know         No                 Yes   \n",
       "1              3500.0        NaN                 Yes   \n",
       "2              1500.0         No                 Yes   \n",
       "3              4200.0        NaN                 Yes   \n",
       "4          Don't Know         No                  No   \n",
       "\n",
       "                grant_from_gov  \n",
       "0             Disability Grant  \n",
       "1  Old Age Pension Grant (OAP)  \n",
       "2    Child Support Grant (CSG)  \n",
       "3    Child Support Grant (CSG)  \n",
       "4                          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7073 entries, 0 to 7072\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   job_in_apr             6426 non-null   object\n",
      " 1   work_in_apr            4954 non-null   object\n",
      " 2   src_income_before_apr  7071 non-null   object\n",
      " 3   lost_income_in_apr     7073 non-null   object\n",
      " 4   total_income_in_apr    7072 non-null   object\n",
      " 5   uif_in_apr             1918 non-null   object\n",
      " 6   grant_from_gov_ques    7072 non-null   object\n",
      " 7   grant_from_gov         1516 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 442.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(swdf.head())\n",
    "print(\"\")\n",
    "display(swdf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Data Wrangling and Data Cleaning\n",
    "\n",
    "In this section, the process of cleaning and wrangling the swdf dataframe of all noise is explained. Firstly, the columns of this dataframe are set to the \"category\" data type, because they all store categorical data. The **total_income_in_apr** was also set to the \"category\" data type for reasons that will be explained in 3.3.2. \n",
    "\n",
    "The cleaning process is similar for all subsequent subsections. First, the **value_counts()** method is ran on a specific column in the swdf dataframe. This method returns the count of all of the unique values in that column. The unique values that are returned are analysed and compared with the kind of values one would expect for that column. If there were any discrepancies between the values that were returned and the kind of values expected, then those values are dealt with in the most appropriate manner. For example, a lot of the columns had meaningless values, such as \"Refused\" or \"Don't know\" for the question that was asked. Those meaningless values were converted to NaN using the **replace_errors()** function. Then, where it was applicable, the rows with NaN values were dropped from the dataframe using the **notna()** function. Where not applicable, those values were **imputed** in the most suitable manner. An example of this can be found in section 3.3.2 and 3.3.3 and will be explained in that section. \n",
    "\n",
    "Once the cleaning and wrangling operations have been completed the number of rows $\\geq$ 50 $*$ (number of columns). Therefore, useful inferences can still be made about the data, despite having so many rows dropped because of NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7073 entries, 0 to 7072\n",
      "Data columns (total 8 columns):\n",
      " #   Column                 Non-Null Count  Dtype   \n",
      "---  ------                 --------------  -----   \n",
      " 0   job_in_apr             6426 non-null   category\n",
      " 1   work_in_apr            4954 non-null   category\n",
      " 2   src_income_before_apr  7071 non-null   category\n",
      " 3   lost_income_in_apr     7073 non-null   category\n",
      " 4   total_income_in_apr    7072 non-null   category\n",
      " 5   uif_in_apr             1918 non-null   category\n",
      " 6   grant_from_gov_ques    7072 non-null   category\n",
      " 7   grant_from_gov         1516 non-null   category\n",
      "dtypes: category(8)\n",
      "memory usage: 83.8 KB\n"
     ]
    }
   ],
   "source": [
    "swdf['job_in_apr'] = swdf['job_in_apr'].astype('category') \n",
    "swdf['work_in_apr'] = swdf['work_in_apr'].astype('category') \n",
    "swdf['src_income_before_apr'] = swdf['src_income_before_apr'].astype('category') \n",
    "swdf['lost_income_in_apr'] = swdf['lost_income_in_apr'].astype('category') \n",
    "swdf['total_income_in_apr'] = swdf['total_income_in_apr'].astype('category') \n",
    "swdf['uif_in_apr'] = swdf['uif_in_apr'].astype('category') \n",
    "swdf['grant_from_gov_ques'] = swdf['grant_from_gov_ques'].astype('category') \n",
    "swdf['grant_from_gov'] = swdf['grant_from_gov'].astype('category') \n",
    "swdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_errors(x):\n",
    "    if x == \"Other\" or x == \"Don't know\" or x == \"Refused\" or x=='Missing' or x== \"Don't Know\" or x==\"DonÃ¢Â€Â™t know\" or x ==\"Other (Specify)\":\n",
    "        return np.NaN\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Wrangling and Cleaning of Employment Data\n",
    "\n",
    "Let's take a look at the unique values of the **job_in_apr** and **work_in_apr** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you have any kind of job in April?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No            4857\n",
       "Yes           1472\n",
       "Refused         87\n",
       "Don't know      10\n",
       "Name: job_in_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the 'job_in_apr' column:  647 \n",
      "\n",
      "Did you work for profit/pay even just for an hour or a small amount in April?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No            4648\n",
       "Yes            185\n",
       "Refused         97\n",
       "Don't know      24\n",
       "Name: work_in_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the 'work_in_apr' column:  2119 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Job in April\n",
    "print('Did you have any kind of job in April?')\n",
    "display(swdf['job_in_apr'].value_counts())\n",
    "print(\"Number of missing values in the 'job_in_apr' column: \", swdf['job_in_apr'].isnull().sum(), \"\\n\")\n",
    "\n",
    "# Work in April \n",
    "print('Did you work for profit/pay even just for an hour or a small amount in April?')\n",
    "display(swdf['work_in_apr'].value_counts())\n",
    "print(\"Number of missing values in the 'work_in_apr' column: \", swdf['work_in_apr'].isnull().sum(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both these columns should only store either a \"Yes\" or a \"No\" value. Therefore, the incorrect values will be cleaned using the process described in 3.2. **job_in_apr** is only missing 9% of its data, whereas **work_in_apr** is missing 30% of its data. \n",
    "Unfortunately, all of the rows with missing values need to be dropped. Due to this data being categorical, one cannot simply impute values for the missing data without making drastic changes in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you have any kind of job in April?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     4857\n",
       "Yes    1472\n",
       "Name: job_in_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did you work for profit/pay even just for an hour or a small amount in April?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     4642\n",
       "Yes     185\n",
       "Name: work_in_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Job in April\n",
    "swdf['job_in_apr'] = swdf['job_in_apr'].apply(replace_errors)\n",
    "swdf = swdf[swdf['job_in_apr'].notna()]\n",
    "print(\"Did you have any kind of job in April?\")\n",
    "display(swdf['job_in_apr'].value_counts())\n",
    "\n",
    "# Work in April\n",
    "swdf['work_in_apr'] = swdf['work_in_apr'].apply(replace_errors)\n",
    "swdf = swdf[swdf['work_in_apr'].notna()]\n",
    "print(\"Did you work for profit/pay even just for an hour or a small amount in April?\")\n",
    "display(swdf['work_in_apr'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Wrangling and Cleaning of Household Income Data\n",
    "\n",
    "Let's take a look at the unique values of the **src_income_before_apr**, **lost_income_in_apr** and **total_income_in_apr** columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was your household's main source of income before lockdown started on 27 March 2020?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Government grants                      1958\n",
       "Income from employment                 1605\n",
       "Household had no income in February     401\n",
       "Money from friends or family            400\n",
       "Income from a business                  314\n",
       "Other (specify)                          76\n",
       "Don't know                               36\n",
       "Refused                                  35\n",
       "Name: src_income_before_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the 'src_income_before_apr' column:  2 \n",
      "\n",
      "\n",
      "Has your household lost its main source of income since the lockdown started on 27 March 2020?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No            2566\n",
       "Yes           2149\n",
       "Don't know     103\n",
       "Refused          9\n",
       "Name: lost_income_in_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the 'lost_income_in_apr' column:  0 \n",
      "\n",
      "\n",
      "What was your household's total income after tax in April?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Don't Know    1622\n",
       "0.0            369\n",
       "Refused        246\n",
       "2000.0         155\n",
       "3000.0         136\n",
       "              ... \n",
       "4350.0           0\n",
       "13600.0          0\n",
       "1360.0           0\n",
       "13500.0          0\n",
       "4169.0           0\n",
       "Name: total_income_in_apr, Length: 460, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in the 'total_income_in_apr' column:  1 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main source of before in April\n",
    "print(\"What was your household's main source of income before lockdown started on 27 March 2020?\")\n",
    "display(swdf['src_income_before_apr'].value_counts())\n",
    "print(\"Number of missing values in the 'src_income_before_apr' column: \", swdf['src_income_before_apr'].isnull().sum(), \"\\n\")\n",
    "print(\"\")\n",
    "\n",
    "# Lost main source of income after April\n",
    "print(\"Has your household lost its main source of income since the lockdown started on 27 March 2020?\")\n",
    "display(swdf['lost_income_in_apr'].value_counts())\n",
    "print(\"Number of missing values in the 'lost_income_in_apr' column: \", swdf['lost_income_in_apr'].isnull().sum(), \"\\n\")\n",
    "print(\"\")\n",
    "\n",
    "# Household income tax after April\n",
    "print(\"What was your household's total income after tax in April?\")\n",
    "display(swdf['total_income_in_apr'].value_counts())\n",
    "print(\"Number of missing values in the 'total_income_in_apr' column: \", swdf['total_income_in_apr'].isnull().sum(), \"\\n\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"Don't know\" and \"Refused\" values in the **src_income_before_apr** and the **lost_income_in_apr** will be removed from these columns using the process described in 3.2, since they make up less than 3% of the data in both columns. In the case of **src_income_before_apr** the \"Other (specify)\" value is still relevant, because a participant could've had another main source of income that was not an option on the survey sheet. Therefore, it will not be removed. In addition, both columns have two missing values between the two of them which can be dropped without significantly affecting the data. \n",
    "\n",
    "In the case of the **total_income_in_apr**, the \"Don't know\" and \"Refused\" values cannot be removed, because they make up the bulk of the data. Furthermore, the **total_income_in_apr** stores numerical data. Therefore, \"Don't know\" and \"Refused\" can't be values within this column, since they are both categorical values. **Mean imputation** is implemented to solve this issue. The \"Don't Know\" and refused values are both set to the mean value of the series. The mean was calculated with those two values excluded  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was your household's main source of income before lockdown started on 27 March 2020?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Government grants                      1958\n",
       "Income from employment                 1605\n",
       "Household had no income in February     401\n",
       "Money from friends or family            400\n",
       "Income from a business                  314\n",
       "Other (specify)                          76\n",
       "Don't know                               36\n",
       "Refused                                  35\n",
       "Name: src_income_before_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Has your household lost its main source of income since the lockdown started on 27 March 2020?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "No     2564\n",
       "Yes    2149\n",
       "Name: lost_income_in_apr, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot cast object dtype to float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mnew_cats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                 \u001b[0mnew_cats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_cats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m             except (\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: \"Don't Know\"",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b45774d990cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mswdf_income\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswdf_income\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mswdf_income\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Don't Know\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mswdf_income\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswdf_income\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mswdf_income\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Refused\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mswdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_income_in_apr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_income_in_apr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswdf_income\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5872\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5873\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5874\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5875\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     ) -> \"BlockManager\":\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     def convert(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_extension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/arrays/categorical.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    435\u001b[0m             ):\n\u001b[1;32m    436\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Cannot cast {self.categories.dtype} dtype to {dtype}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtake_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_cats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibalgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_platform_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_codes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot cast object dtype to float64"
     ]
    }
   ],
   "source": [
    "# Source of income before April \n",
    "# swdf['src_income_before_apr'] = swdf['src_income_before_apr'].apply(replace_errors)\n",
    "swdf = swdf[swdf['src_income_before_apr'].notna()]\n",
    "print(\"What was your household's main source of income before lockdown started on 27 March 2020?\")\n",
    "display(swdf['src_income_before_apr'].value_counts())\n",
    "\n",
    "# Lost main source of income after April\n",
    "swdf['lost_income_in_apr'] = swdf['lost_income_in_apr'].apply(replace_errors)\n",
    "swdf = swdf[swdf['lost_income_in_apr'].notna()]\n",
    "print(\"Has your household lost its main source of income since the lockdown started on 27 March 2020?\")\n",
    "display(swdf['lost_income_in_apr'].value_counts())\n",
    "\n",
    "# Household income tax after April\n",
    "swdf_income = swdf['total_income_in_apr']\n",
    "swdf_income = swdf_income[swdf_income != \"Don't Know\"]\n",
    "swdf_income = swdf_income[swdf_income != \"Refused\"]\n",
    "swdf['total_income_in_apr'] = swdf['total_income_in_apr'].astype('float64') \n",
    "\n",
    "mean = round(swdf_income.mean(),0)\n",
    "\n",
    "swdf['total_income_in_apr'] = swdf['total_income_in_apr'].replace(to_replace =\"Don't Know\", value=mean)\n",
    "swdf['total_income_in_apr'] = swdf['total_income_in_apr'].replace(to_replace =\"Refused\", value=mean)\n",
    "display(swdf['total_income_in_apr'].value_counts())\n",
    "swdf = swdf[swdf['total_income_in_apr'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Wrangling and Cleaning of Grant Data\n",
    "\n",
    "Let's take a look at the unique values of the **src_income_before_apr**, **lost_income_in_apr** and **total_income_in_apr** columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Did you receive the UIF reduced work time benefit in April?\")\n",
    "display(swdf['uif_in_apr'].value_counts())\n",
    "print(\"Number of missing values in 'uif_in_apr': \", swdf['uif_in_apr'].isnull().sum(), '\\n')\n",
    "\n",
    "print(\"Did you receive any kind of grant from the government in April?\")\n",
    "display(swdf['grant_from_gov_ques'].value_counts())\n",
    "print(\"Number of missing values in 'grant_from_gov_ques': \", swdf['grant_from_gov_ques'].isnull().sum(), '\\n')\n",
    "\n",
    "print(\"If you did receive a grant from the government in April, what kind of grant did you receive?\")\n",
    "display(swdf['grant_from_gov'].value_counts())\n",
    "print(\"Number of missing values in 'grant_from_gov': \", swdf['grant_from_gov'].isna().sum(), '\\n')\n",
    "print(\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting observation is that the **grant_from_gov_ques** has no missing values. We can use this column to **impute** missing values in the **uif_in_apr** column. In this case we are assuming that if someone responded \"No\" to receiving any kind of grant from the government, then this implies that they did not receive the reduced work time benefit in April. For the **grant_from_gov_ques** we again remove the \"Refused\" and \"Don't know\" values. \n",
    "\n",
    "Also note that **'grant_from_gov'** missing 3681 values is correct. In the **grant_from_gov_ques** only 966 participants responded with \"Yes\". For the participant to be able to stipulate what kind of grant they received from the government they had to have had first received a grant from the government. The 3681 missing values are of participants who did not receive a grant from the government. Only the updated columns are represented in the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values for uif_in_apr and remove incorrect values\n",
    "swdf.uif_in_apr.fillna(swdf.grant_from_gov_ques, inplace=True)\n",
    "swdf['uif_in_apr'] = swdf['uif_in_apr'].apply(replace_errors)\n",
    "swdf = swdf[swdf['uif_in_apr'].notna()]\n",
    "print(\"Did you receive the UIF reduced work time benefit in April?\")\n",
    "display(swdf['uif_in_apr'].value_counts())\n",
    "\n",
    "# Remove unwanted results in grant_from_gov_ques\n",
    "swdf['grant_from_gov_ques'] = swdf['grant_from_gov_ques'].apply(replace_errors)\n",
    "swdf = swdf[swdf['grant_from_gov_ques'].notna()]\n",
    "grant_from_gov_ques = swdf['grant_from_gov_ques'] \n",
    "print(\"Did you receive any kind of grant from the government in April?\")\n",
    "display(swdf['grant_from_gov_ques'].value_counts())\n",
    "\n",
    "# Types of grants\n",
    "swdf['grant_from_gov'] = swdf['grant_from_gov'].apply(replace_errors)\n",
    "swdf = swdf[swdf['grant_from_gov'].notna()]\n",
    "print(\"If you did receive a grant from the government in April, what kind of grant did you receive?\")\n",
    "display(swdf['grant_from_gov'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Data Exploration and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains an investigation of the now cleaned and wrangled swdf dataframe. The exploration and analysis will look at 2 main components: grants received from the government and household income during April 2020. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Exploration and Analysis of UIF and Other Grants in April"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the mandated lockdown of 27 March 2020 many people were not able to go to work. To assist those that had now found themselves unemployed, the South African government stated that it would make available a UIF reduced work-time benefit in April 2020. The following three cells investigate the number of unemployed participants that actually received this benefit from the government during this time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have been eligible to have received the UIF reduced work time benefit in April 2020 one must have either had their working hours reduced or have had lost their job during this time. The upcoming cell initializes an **unemployed_swdf** dataframe that only stores the data of participants that were unemployed during April 2020 (ie: the values in the **job_in_apr** and **work_in_apr** are both \"No\" for this subset of participants). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed_swdf = swdf.loc[(swdf['job_in_apr']=='No') & (swdf['work_in_apr']=='No')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployed_swdf = unemployed_swdf['uif_in_apr'].value_counts()/len(unemployed_swdf['uif_in_apr'])\n",
    "plt.figure(figsize=(10,6))\n",
    "unemployed_swdf.plot(kind='bar');\n",
    "plt.title(\"Did You Receive A UIF Reduced Work-Time Benefit in April?\");\n",
    "plt.xlabel(\"Response\"); plt.ylabel(\"Proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is fair to assume that most (if not all) unemployed participants in the sample would have not only been eligible to receive this benefit from the government during this time. It is also fair to assume that they would have applied for this benefit. However, less than 20% of unemployed participants received this benefit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three cells investigate the other kinds of grants participants received from government during the inital stages of the Covid-19 pandemic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_from_gov_ques = grant_from_gov_ques.value_counts()/len(grant_from_gov_ques)\n",
    "plt.figure(figsize=(10,6))\n",
    "grant_from_gov_ques.plot(kind='bar');\n",
    "plt.title(\"Did you receive any kind of grant from the government in April?\");\n",
    "plt.xlabel(\"Response\"); plt.ylabel(\"Proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 20% of the sample space actually receieved any kind of grant from the government during April 2020. What kind of grants were these? And what kind of person was most likely to receive a grant from the government at this time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_from_gov = swdf['grant_from_gov'].value_counts()/len(swdf['grant_from_gov'])\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(y = grant_from_gov.index, x = grant_from_gov.values)\n",
    "plt.xlabel('Proportion')\n",
    "plt.title(\"If you did receive a grant from the government in April, what kind of grant did you receive?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 40% of the sample received the Child Support Grant (CSG), and the second most receieved grant was the Old Age Pension Grant (OAP). A quick observation that could be made from this is that senior citizens and those with children were more likely to receive a grant from the government during this time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Exploration and Analysis of Household Income in April"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we explore the different ways that participants earn an income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "src_income_before_apr = swdf['src_income_before_apr'].value_counts()/len(swdf['src_income_before_apr'])\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(y = src_income_before_apr.index, x = src_income_before_apr.values)\n",
    "plt.xlabel('Proportion')\n",
    "plt.title(\"What was your household's main source of income before lockdown started on 27 March 2020?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An interesting observation is that over 60% of the participants stated that their main source of income came from government grants, yet only 20% of them actually received a grant from the government."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_income_in_apr = swdf['lost_income_in_apr'].value_counts()/len(swdf['lost_income_in_apr'])\n",
    "plt.figure(figsize=(10,6))\n",
    "lost_income_in_apr.plot(kind='bar');\n",
    "plt.title(\"Has your household lost its main source of income since the lockdown started on 27 March 2020?\");\n",
    "plt.xlabel(\"Response\"); plt.ylabel(\"Proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only about 40% of people had their income decreased. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
